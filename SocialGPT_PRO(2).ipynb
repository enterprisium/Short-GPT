{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1BRPGVwfbt"
      },
      "source": [
        "\n",
        "\n",
        "## <img src='https://raw.githubusercontent.com/UndeadSec/SocialFishMobile/master/content/logo.png' height=\"30\" alt=\"SocialFish\" /> SocialFish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tVcSpw5wx_jX"
      },
      "outputs": [],
      "source": [
        "#@markdown <h3>⬅️ Click Here to START</h3>\n",
        "#@markdown <br><center><img src='https://raw.githubusercontent.com/UndeadSec/SocialFishMobile/master/content/logo.png' height=\"100\" alt=\"SocialFish\"/></center>\n",
        "#@markdown <center><h3>SocialGPT<br />Content Automation Tool & Desigend To Convert Audio into Video</h3></center><br>\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def play(f):\n",
        "    mp4 = open(f, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(\"\"\"\n",
        "    <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url)\n",
        "\n",
        "# Install required packages\n",
        "subprocess.run(['apt', 'install', 'imagemagick'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['cat', '/etc/ImageMagick-6/policy.xml', '|', 'sed', 's/none/read,write/g', '>', '/etc/ImageMagick-6/policy.xml'])\n",
        "subprocess.run(['wget', '-qO-', 'http://keyserver.ubuntu.com/pks/lookup?op=get&search=0x6888550b2fc77d09', '|', 'sudo', 'tee', '/etc/apt/trusted.gpg.d/songrec.asc'])\n",
        "subprocess.run(['sudo', 'apt-add-repository', 'ppa:marin-m/songrec', '-y', '-u'])\n",
        "subprocess.run(['sudo', 'apt', 'install', 'songrec', '-y'])\n",
        "subprocess.run(['pip', 'install', 'youtube-transcript-api', 'langchain', 'langchain_openai', 'openai', 'requests', 'moviepy==2.0.0.dev2', 'imageio==2.25.1', 'pysrt==1.1.2', 'Pillow==9.5.0', 'ffmpeg-python', 'pytube', 'google-api-python-client', 'google-auth-oauthlib', 'google-auth-httplib2', 'oauth2client', 'git+https://github.com/m1guelpf/auto-subtitle.git'])\n",
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xvIxkIPvOsn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0554bb-7f9b-4b08-87b7-d6130bf66c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'output' created successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "OPENAI_API_KEY = \"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\"  #@param {type:\"string\"}\n",
        "PEXELS_API_KEY = \"7KygQ5mPe95mQGiO0Fds3taAlOZSuwdwsJQ12SeSaGJo6GeVaP70shik\" #@param {type:\"string\"}\n",
        "#CLIENT_SECRETS = \"\" #@param {type:\"string\"}\n",
        "INPUT_MEDIA = \"/content/drive/MyDrive/ENGTEST.mp4\"  #@param {type:\"string\"}\n",
        "BG_MUSIC = \"\"  # @param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"PEXELS_API_KEY\"] = PEXELS_API_KEY\n",
        "#os.environ[\"CLIENT_SECRETS\"] = CLIENT_SECRETS\n",
        "#####################################\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "directory_path = \"output\"\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Directory '{directory_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Directory '{directory_path}' already exists.\")\n",
        "# Clean all logs\n",
        "shutil.rmtree('/content/logs', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BER5GoXZGQeQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N_lkWTNvaJW",
        "outputId": "1825483c-b771-43ef-8350-7ad218e33e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voice Generated: voice.mp3 | Duration: 43s\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import AudioFileClip\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the path where the voice will be saved\n",
        "voice_path = \"output/voice.mp3\"\n",
        "\n",
        "# Check if the input media path is provided\n",
        "if INPUT_MEDIA.strip() == \"\":\n",
        "    # Generate TTS voice based on the predefined script\n",
        "    client = OpenAI()\n",
        "    response = client.audio.speech.create(\n",
        "        model=\"tts-1-hd\",\n",
        "        voice=\"onyx\",\n",
        "        input=script,\n",
        "    )\n",
        "\n",
        "    # Write the generated TTS voice to the voice_path\n",
        "    with open(voice_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    # Copy the provided input media to the output directory and rename it as voice.mp3\n",
        "    output_dir = \"/content/output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Copy the provided input media to the output directory and rename it as voice.mp3\n",
        "    shutil.copy(INPUT_MEDIA, voice_path)\n",
        "\n",
        "#####################################\n",
        "\n",
        "# Get the duration of input media\n",
        "audio = AudioFileClip(voice_path)\n",
        "duration_in_seconds = round(audio.duration)\n",
        "\n",
        "# Print the name of the voiceover file and its duration\n",
        "print(f\"Voice Generated: {voice_path.split('/')[-1]} | Duration: {duration_in_seconds}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps-Sg10bxgkp"
      },
      "outputs": [],
      "source": [
        "#####################################\n",
        "# Generating Captions please change the input media file language\n",
        "\n",
        "!auto_subtitle \"output/voice.mp3\" --srt_only \"True\" --output_dir \"output\" --language \"en\"\n",
        "import pysrt\n",
        "import string\n",
        "\n",
        "subs = pysrt.open('output/voice.srt')\n",
        "for sub in subs:\n",
        "    sub.text = sub.text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    if len(sub.text) > 20:\n",
        "        words = sub.text.split()\n",
        "        lines = []\n",
        "        current_line = \"\"\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) <= 30:\n",
        "                current_line += word.title() + \" \"\n",
        "            else:\n",
        "                lines.append(current_line.strip())\n",
        "                current_line = word.title() + \" \"\n",
        "        if current_line:\n",
        "            lines.append(current_line.strip())\n",
        "        sub.text = \"\\n\".join(lines)\n",
        "    else:\n",
        "        sub.text = sub.text.title()\n",
        "subs.save(\"output/voice.srt\")\n",
        "#might take some time (approx 3- 5min depending on audio length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoTlYYwp3SnK",
        "outputId": "1965b7a9-6083-4c1d-b3b5-1bd8a5380a1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Laugh',\n",
              " 'River',\n",
              " 'Journey',\n",
              " 'Adventure',\n",
              " 'Love',\n",
              " 'Nature',\n",
              " 'Ocean',\n",
              " 'Dream',\n",
              " 'Paradise']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "template = \"\"\"Imagine you're a highly imaginative artist with the unique ability to map the subjects\n",
        "in a given SRT caption to a one word real-world objects and scenes.\n",
        "It's important to keep the titles exactly one word, and title must be a real word object or scences\n",
        "That human can vision, avoid providing teoritocal titles like: Paradox, Chrysalis, Journey, Reality, Accomplishment\n",
        "Instead use real world titles that can bee seen by human eyes like Mansion, Yoga, Car, Money.\n",
        "Give me exactly {num_clips} distinct clip titles.\n",
        "Each title should seamlessly flow into the next, creating a captivating narrative,\n",
        "and each title will be precisely 5 seconds long.\n",
        "I want you to understand and imagine the big picture of the video and give me titles that matches\n",
        "The entire video, not just invidual scences.\n",
        "\n",
        "Get inspired by the SRT caption provided:\n",
        "\n",
        "{srt_caption}\n",
        "\n",
        "Output Instruction:\n",
        "Provide only the titles. Each title must be separated by a new line,\n",
        "do not mention numbers in titles and titles must be URL-encoded friendly.\n",
        "Example Output:\n",
        "Yoga\n",
        "Forest\n",
        "Office\n",
        "Jogging\n",
        "Sunset\n",
        "Cafe\n",
        "Hiking\n",
        "Spa\n",
        "Beach\n",
        "Tea\n",
        "Luxury\n",
        "Money\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "num_clips = (duration_in_seconds // 5) + 1\n",
        "\n",
        "with open(\"output/voice.srt\", \"r\") as f:\n",
        "  srt_caption = f.read()\n",
        "  output = chain.invoke({\"num_clips\": num_clips, \"srt_caption\": srt_caption})\n",
        "\n",
        "clips_titles = output.strip().split(\"\\n\")\n",
        "clips_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o17lfo7PrV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1215725-731f-47ed-9947-6f9194a930ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['output/Laugh_0.mp4',\n",
              " 'output/River_0.mp4',\n",
              " 'output/Journey_0.mp4',\n",
              " 'output/Adventure_0.mp4',\n",
              " 'output/Love_0.mp4',\n",
              " 'output/Nature_0.mp4',\n",
              " 'output/Ocean_0.mp4',\n",
              " 'output/Dream_0.mp4',\n",
              " 'output/Paradise_0.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import requests\n",
        "from collections import Counter\n",
        "from moviepy.editor import AudioFileClip\n",
        "\n",
        "\n",
        "clip_counter = Counter(clips_titles)\n",
        "clips_paths = []\n",
        "selected_videos = set()\n",
        "\n",
        "for title, count in clip_counter.items():\n",
        "    headers = {\n",
        "        \"Authorization\": os.environ[\"PEXELS_API_KEY\"],\n",
        "    }\n",
        "    url = f\"https://api.pexels.com/videos/search?query={title}&per_page=15&orientation=portrait&size=medium\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        videos = response.json()[\"videos\"]\n",
        "        for i in range(count):\n",
        "            available_videos = [\n",
        "                video\n",
        "                for video in videos\n",
        "                if video[\"video_files\"][0][\"link\"] not in selected_videos\n",
        "            ]\n",
        "            if not available_videos:\n",
        "                print(f\"No more available videos for title '{title}'.\")\n",
        "                break\n",
        "\n",
        "            video = random.choice(available_videos)\n",
        "            video_url = video[\"video_files\"][0][\"link\"]\n",
        "            temp_name = f\"{title}_{i}.mp4\"\n",
        "            video_path = os.path.join(\"output\", temp_name)\n",
        "            with open(video_path, \"wb\") as video_file:\n",
        "                video_file.write(requests.get(video_url).content)\n",
        "            clips_paths.append(video_path)\n",
        "            selected_videos.add(video_url)\n",
        "    else:\n",
        "        print(\n",
        "            f\"Failed to fetch videos for title '{title}'. Status code: {response.status_code}\"\n",
        "        )\n",
        "\n",
        "for i in range(num_clips - len(clips_paths)):\n",
        "  clips_paths.append(clips_paths[0])\n",
        "\n",
        "clips_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlqM7fJ-2NIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9a45fe-69e2-492c-b105-58e76e74534f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e970550>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e971a80>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e9719c0>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e972800>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e970100>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e972a10>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e970640>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e971510>,\n",
              " <moviepy.video.io.VideoFileClip.VideoFileClip at 0x78f69e972e00>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from moviepy.video.fx.all import resize\n",
        "\n",
        "\n",
        "def resize_clip(input_video_path, duration=5, new_dimensions = (720, 1280)):\n",
        "    video_clip = VideoFileClip(input_video_path)\n",
        "    total_duration = video_clip.duration\n",
        "    start_time = (total_duration - duration) / 2\n",
        "    end_time = start_time + duration\n",
        "    video_clip = video_clip.subclip(start_time, end_time)\n",
        "\n",
        "    video_clip = resize(video_clip, new_dimensions)\n",
        "    return video_clip\n",
        "\n",
        "\n",
        "clips = [resize_clip(cp) for cp in clips_paths]\n",
        "clips\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5kF_C-74sdv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from moviepy.editor import VideoFileClip, CompositeAudioClip, concatenate_videoclips, AudioFileClip\n",
        "from moviepy.audio.fx.all import volumex\n",
        "\n",
        "# Ensure the 'output' directory exists\n",
        "if not os.path.exists('output'):\n",
        "    os.makedirs('output')\n",
        "\n",
        "# Initialize an empty music_audio variable\n",
        "music_audio = None\n",
        "\n",
        "# Check if BG_MUSIC is provided\n",
        "if BG_MUSIC.strip():\n",
        "    # Download the background music\n",
        "    music_response = requests.get(BG_MUSIC)\n",
        "\n",
        "    # Save the music file to 'output/music.mp3'\n",
        "    with open('output/music.mp3', 'wb') as music_file:\n",
        "        music_file.write(music_response.content)\n",
        "\n",
        "    # Load and process the background music\n",
        "    music_audio = AudioFileClip(\"output/music.mp3\").fx(volumex, 0.3)  # Adjusted volume level to 0.3\n",
        "    t_start = int(music_audio.duration // 2 - duration_in_seconds // 2)\n",
        "    music_audio = music_audio.subclip(t_start, duration_in_seconds + t_start)\n",
        "\n",
        "# Load and process the voice audio\n",
        "voice_audio = AudioFileClip(\"output/voice.mp3\").fx(volumex, 3)\n",
        "\n",
        "# Combine the voice audio with background music if it exists\n",
        "if music_audio:\n",
        "    audio = CompositeAudioClip([voice_audio, music_audio])\n",
        "else:\n",
        "    audio = voice_audio\n",
        "\n",
        "\n",
        "# Uncomment the following line and ensure it correctly concatenates the video clips\n",
        "final_clip = concatenate_videoclips(clips, method=\"compose\").subclip(0, duration_in_seconds)\n",
        "\n",
        "# Set the audio for the final clip\n",
        "final_clip = final_clip.set_audio(audio)\n",
        "\n",
        "# Write the final video file\n",
        "final_clip.write_videofile(\"output/composite_video.mp4\", codec=\"libx264\", audio_codec=\"aac\", fps=24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LkTCGDI7GER"
      },
      "outputs": [],
      "source": [
        "play(\"output/composite_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import TextClip, CompositeVideoClip\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "\n",
        "video = VideoFileClip(\"output/composite_video.mp4\")\n",
        "watermark_clip = TextClip(\"@Enterprisium\", font=\"Nimbus-Sans-Bold\", fontsize=24,\n",
        "                          color='white', size=(640, 480)).set_duration(video.duration)\n",
        "generator = lambda txt: TextClip(txt, font=\"Nimbus-Sans-Bold\", fontsize=36,\n",
        "                                 color='white', size=(video.w, video.h),\n",
        "                                 stroke_color='black', stroke_width=1.5)\n",
        "subtitles = SubtitlesClip(\"output/voice.srt\", generator)\n",
        "result = CompositeVideoClip([video, subtitles.set_position(('center')),\n",
        "                             watermark_clip.set_position(('center', 'bottom'))])\n",
        "result.write_videofile(\"output/out.mp4\", fps=video.fps, codec=\"libx264\",\n",
        "                       audio_codec=\"aac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM2ajXM5kFEB",
        "outputId": "2dbba9b6-c820-4d46-e4f8-3b8f457a0f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video output/out.mp4.\n",
            "MoviePy - Writing audio in outTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output/out.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output/out.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "play(\"output/out.mp4\")"
      ],
      "metadata": {
        "id": "1BmjQR-Y5x_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "\n",
        "# Customizable variables for the video\n",
        "video_path = \"output/composite_video.mp4\"\n",
        "subtitles_file = \"output/voice.srt\"\n",
        "\n",
        "# Customizable variables for the watermark\n",
        "watermark_text = \"@Enterprisium\"\n",
        "watermark_font = \"Nimbus-Sans-Bold\"\n",
        "watermark_fontsize = 50\n",
        "watermark_color = \"white\"\n",
        "watermark_position = (\"center\", \"bottom\")  # Position can be changed as needed\n",
        "\n",
        "# Customizable variables for subtitles\n",
        "subtitle_font = \"Nimbus-Sans-Bold\"\n",
        "subtitle_fontsize = 50\n",
        "subtitle_color = \"white\"\n",
        "subtitle_stroke_color = \"black\"\n",
        "subtitle_stroke_width = 1.5\n",
        "subtitle_position = (\"center\")  # Position can be changed as needed\n",
        "\n",
        "# Load the main video file\n",
        "video = VideoFileClip(video_path)\n",
        "\n",
        "# Create a watermark text clip using the customizable variables\n",
        "watermark_clip = TextClip(watermark_text, font=watermark_font, fontsize=watermark_fontsize,\n",
        "                          color=watermark_color, size=(640, 480)).set_duration(video.duration).set_position(watermark_position)\n",
        "\n",
        "# Define a generator function for subtitles styling using the customizable variables\n",
        "generator = lambda txt: TextClip(txt, font=subtitle_font, fontsize=subtitle_fontsize,\n",
        "                                 color=subtitle_color, size=(video.w, video.h),\n",
        "                                 stroke_color=subtitle_stroke_color, stroke_width=subtitle_stroke_width)\n",
        "\n",
        "# Load subtitles from a .srt file and apply the styling from the generator function\n",
        "subtitles = SubtitlesClip(subtitles_file, generator).set_position(subtitle_position)\n",
        "\n",
        "# Composite the video, subtitles, and watermark together\n",
        "result = CompositeVideoClip([video, subtitles, watermark_clip])\n",
        "\n",
        "# Export the final video\n",
        "output_path = \"output/out.mp4\"  # Customizable output file path\n",
        "result.write_videofile(output_path, fps=video.fps, codec=\"libx264\", audio_codec=\"aac\")"
      ],
      "metadata": {
        "id": "YMeWk0UF_G2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}